{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPDunMICK42mhp/rbjM23Hv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheDarkNight21/blues-clues---HVAC-note-extractor/blob/main/train_detectron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 1: load datasets"
      ],
      "metadata": {
        "id": "1FnUauew9SaH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BOARlUX6YMG",
        "outputId": "26c017c3-f289-4621-8927-16c5c066fdcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "dataset_upscaled_dir = '/content/gdrive/My Drive/blues clues/datasets/blueprint_notes_upscaled'\n",
        "dataset_rescaled_dir = '/content/gdrive/My Drive/blues clues/datasets/blueprint_notes_rescaled'\n",
        "dataset_notes_dir = '/content/gdrive/My Drive/blues clues/datasets/blueprint_notes'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "drive_path = dataset_upscaled_dir\n",
        "\n",
        "if os.path.isdir(drive_path):\n",
        "    print(f\"'{drive_path}' is mounted and accessible.\")\n",
        "    print(\"Files in My Drive:\", os.listdir(drive_path)[:10]) # Print first 10 files/folders\n",
        "else:\n",
        "    print(f\"'{drive_path}' is not accessible. Drive may not be mounted correctly.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tARjiB148qXx",
        "outputId": "abcf6c35-6cf9-4087-d835-aa41314a2e48"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/gdrive/My Drive/blues clues/datasets/blueprint_notes_upscaled' is mounted and accessible.\n",
            "Files in My Drive: ['annotations']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 2: load detectron2 model and necessary functions"
      ],
      "metadata": {
        "id": "TUUCIUtJ9Ui4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install detectron2 dependencies\n",
        "!pip install torch torchvision\n",
        "\n",
        "# Install detectron2 from source (recommended for Colab)\n",
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "# Restart runtime after installation (Colab menu: Runtime > Restart runtime)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSZ3UcbD9CHP",
        "outputId": "f1837c99-66e9-4a3e-9df0-e1c464184c15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-gk9rawrz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-gk9rawrz\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit fd27788985af0f4ca800bca563acdb700bb890e2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (2.0.11)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (3.3.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (3.1.2)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (2.19.0)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black (from detectron2==0.6)\n",
            "  Downloading black-26.1.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.9/88.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (25.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from black->detectron2==0.6) (8.3.1)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=1.0.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-1.0.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.12/dist-packages (from black->detectron2==0.6) (4.5.1)\n",
            "Collecting pytokens>=0.3.0 (from black->detectron2==0.6)\n",
            "  Downloading pytokens-0.4.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (3.1.5)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard->detectron2==0.6) (4.15.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.3)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading black-26.1.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pathspec-1.0.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.0/55.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytokens-0.4.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (268 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.9/268.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: detectron2, fvcore\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp312-cp312-linux_x86_64.whl size=7085024 sha256=56f58df729ad81bc61436eb479db115ae7dadfbf647e39d779bffc4db584da10\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-js1dvdnm/wheels/d3/6e/bd/1969578f1456a6be2d6f083da65c669f450b23b8f3d1ac14c1\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=a4cebe414264b69315f2088637159b32886a18261858179264b8037d1e2fbf27\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n",
            "Successfully built detectron2 fvcore\n",
            "Installing collected packages: yacs, pytokens, portalocker, pathspec, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "Successfully installed black-26.1.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.1.0 pathspec-1.0.3 portalocker-3.2.0 pytokens-0.4.0 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Register Datasets ---\n",
        "\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "register_coco_instances(\n",
        "    \"blueprint_train\",\n",
        "    {},\n",
        "    f\"{dataset_rescaled_dir}/annotations/instances_train.json\",\n",
        "    f\"{dataset_rescaled_dir}/train\"\n",
        ")\n",
        "\n",
        "register_coco_instances(\n",
        "    \"blueprint_val\",\n",
        "    {},\n",
        "    f\"{dataset_rescaled_dir}/annotations/instances_val.json\",\n",
        "    f\"{dataset_rescaled_dir}/val\"\n",
        ")"
      ],
      "metadata": {
        "id": "FO19IN1v98vh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Setup Configuration ---\n",
        "\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "\n",
        "cfg.MODEL.DEVICE = \"cuda\"\n",
        "print(f\"Using device: {cfg.MODEL.DEVICE}\")\n",
        "\n",
        "cfg.DATASETS.TRAIN = (\"blueprint_train\",)\n",
        "cfg.DATASETS.TEST = (\"blueprint_val\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2 # good for t4 gpu\n",
        "\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 1000\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
        "\n",
        "cfg.SOLVER.LOG_PERIOD = 50\n",
        "cfg.TEST.EVAL_PERIOD = 500\n",
        "\n",
        "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/output_blueprints\"\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIhlNBbv_8cU",
        "outputId": "e8f526be-d5df-4150-c1d6-6cf9968f520e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Train the Model ---\n",
        "\n",
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\nTraining finished.\")\n",
        "print(f\"To see training graphs, run the following command in your terminal:\")\n",
        "print(f\"tensorboard --logdir {cfg.OUTPUT_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzxp0dzrAkH8",
        "outputId": "f91b2022-b0c0-431a-ef58-9d178a951b8f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01/19 16:21:14 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [01/19 16:21:14 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[01/19 16:21:14 d2.data.datasets.coco]: Loaded 68 images in COCO format from /content/gdrive/My Drive/blues clues/datasets/blueprint_notes_rescaled/annotations/instances_train.json\n",
            "[01/19 16:21:14 d2.data.build]: Removed 0 images with no usable annotations. 68 images left.\n",
            "[01/19 16:21:14 d2.data.build]: Distribution of instances among all 2 categories:\n",
            "|   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:----------:|:-------------|\n",
            "| General Not.. | 62           | Sheet Name | 68           |\n",
            "|               |              |            |              |\n",
            "|     total     | 130          |            |              |\n",
            "[01/19 16:21:14 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[01/19 16:21:14 d2.data.build]: Using training sampler TrainingSampler\n",
            "[01/19 16:21:14 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[01/19 16:21:14 d2.data.common]: Serializing 68 elements to byte tensors and concatenating them all ...\n",
            "[01/19 16:21:14 d2.data.common]: Serialized dataset takes 0.03 MiB\n",
            "[01/19 16:21:14 d2.data.build]: Making batched data loader with batch_size=2\n",
            "WARNING [01/19 16:21:14 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[01/19 16:21:14 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model_final_280758.pkl: 167MB [00:00, 240MB/s]                           \n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01/19 16:21:15 d2.engine.train_loop]: Starting training from iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "W0119 16:21:19.595000 424 torch/fx/_symbolic_trace.py:52] is_fx_tracing will return true for both fx.symbolic_trace and torch.export. Please use is_fx_tracing_symbolic_tracing() for specifically fx.symbolic_trace or torch.compiler.is_compiling() for specifically torch.export/compile.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01/19 16:21:30 d2.utils.events]:  eta: 0:08:39  iter: 19  total_loss: 1.002  loss_cls: 0.8066  loss_box_reg: 0.01142  loss_rpn_cls: 0.1577  loss_rpn_loc: 0.01038    time: 0.5496  last_time: 0.5086  data_time: 0.2163  last_data_time: 0.1132   lr: 4.9953e-06  max_mem: 2424M\n",
            "[01/19 16:21:46 d2.utils.events]:  eta: 0:08:13  iter: 39  total_loss: 0.9842  loss_cls: 0.7066  loss_box_reg: 0.06188  loss_rpn_cls: 0.191  loss_rpn_loc: 0.009734    time: 0.5254  last_time: 0.4584  data_time: 0.1022  last_data_time: 0.0072   lr: 9.9902e-06  max_mem: 2424M\n",
            "[01/19 16:21:54 d2.utils.events]:  eta: 0:07:06  iter: 59  total_loss: 0.775  loss_cls: 0.5453  loss_box_reg: 0.07122  loss_rpn_cls: 0.1217  loss_rpn_loc: 0.009123    time: 0.4865  last_time: 0.4929  data_time: 0.0075  last_data_time: 0.0121   lr: 1.4985e-05  max_mem: 2424M\n",
            "[01/19 16:22:03 d2.utils.events]:  eta: 0:06:46  iter: 79  total_loss: 0.6286  loss_cls: 0.4091  loss_box_reg: 0.1067  loss_rpn_cls: 0.09351  loss_rpn_loc: 0.009418    time: 0.4692  last_time: 0.4400  data_time: 0.0060  last_data_time: 0.0058   lr: 1.998e-05  max_mem: 2424M\n",
            "[01/19 16:22:11 d2.utils.events]:  eta: 0:06:29  iter: 99  total_loss: 0.6884  loss_cls: 0.376  loss_box_reg: 0.2428  loss_rpn_cls: 0.07328  loss_rpn_loc: 0.01075    time: 0.4612  last_time: 0.4294  data_time: 0.0071  last_data_time: 0.0102   lr: 2.4975e-05  max_mem: 2424M\n",
            "[01/19 16:22:20 d2.utils.events]:  eta: 0:06:20  iter: 119  total_loss: 0.791  loss_cls: 0.4001  loss_box_reg: 0.3292  loss_rpn_cls: 0.02204  loss_rpn_loc: 0.006353    time: 0.4535  last_time: 0.4529  data_time: 0.0069  last_data_time: 0.0192   lr: 2.997e-05  max_mem: 2424M\n",
            "[01/19 16:22:28 d2.utils.events]:  eta: 0:06:09  iter: 139  total_loss: 0.885  loss_cls: 0.414  loss_box_reg: 0.4346  loss_rpn_cls: 0.01656  loss_rpn_loc: 0.006586    time: 0.4482  last_time: 0.3588  data_time: 0.0067  last_data_time: 0.0052   lr: 3.4965e-05  max_mem: 2424M\n",
            "[01/19 16:22:37 d2.utils.events]:  eta: 0:06:02  iter: 159  total_loss: 0.9256  loss_cls: 0.397  loss_box_reg: 0.4824  loss_rpn_cls: 0.01195  loss_rpn_loc: 0.00684    time: 0.4467  last_time: 0.4468  data_time: 0.0075  last_data_time: 0.0054   lr: 3.996e-05  max_mem: 2424M\n",
            "[01/19 16:22:45 d2.utils.events]:  eta: 0:05:53  iter: 179  total_loss: 0.9781  loss_cls: 0.3789  loss_box_reg: 0.5706  loss_rpn_cls: 0.007485  loss_rpn_loc: 0.006851    time: 0.4447  last_time: 0.4650  data_time: 0.0053  last_data_time: 0.0059   lr: 4.4955e-05  max_mem: 2424M\n",
            "[01/19 16:22:54 d2.utils.events]:  eta: 0:05:44  iter: 199  total_loss: 1.034  loss_cls: 0.3878  loss_box_reg: 0.5872  loss_rpn_cls: 0.008516  loss_rpn_loc: 0.007872    time: 0.4442  last_time: 0.4266  data_time: 0.0081  last_data_time: 0.0048   lr: 4.995e-05  max_mem: 2426M\n",
            "[01/19 16:23:03 d2.utils.events]:  eta: 0:05:36  iter: 219  total_loss: 0.9623  loss_cls: 0.362  loss_box_reg: 0.5909  loss_rpn_cls: 0.008627  loss_rpn_loc: 0.004869    time: 0.4441  last_time: 0.4940  data_time: 0.0064  last_data_time: 0.0132   lr: 5.4945e-05  max_mem: 2426M\n",
            "[01/19 16:23:12 d2.utils.events]:  eta: 0:05:28  iter: 239  total_loss: 1.007  loss_cls: 0.3657  loss_box_reg: 0.6334  loss_rpn_cls: 0.01054  loss_rpn_loc: 0.007756    time: 0.4427  last_time: 0.4939  data_time: 0.0058  last_data_time: 0.0049   lr: 5.994e-05  max_mem: 2426M\n",
            "[01/19 16:23:21 d2.utils.events]:  eta: 0:05:20  iter: 259  total_loss: 0.99  loss_cls: 0.333  loss_box_reg: 0.6127  loss_rpn_cls: 0.009637  loss_rpn_loc: 0.006762    time: 0.4436  last_time: 0.4415  data_time: 0.0063  last_data_time: 0.0052   lr: 6.4935e-05  max_mem: 2426M\n",
            "[01/19 16:23:30 d2.utils.events]:  eta: 0:05:12  iter: 279  total_loss: 0.8787  loss_cls: 0.2784  loss_box_reg: 0.5836  loss_rpn_cls: 0.006152  loss_rpn_loc: 0.006985    time: 0.4446  last_time: 0.5139  data_time: 0.0058  last_data_time: 0.0057   lr: 6.993e-05  max_mem: 2426M\n",
            "[01/19 16:23:39 d2.utils.events]:  eta: 0:05:03  iter: 299  total_loss: 0.8792  loss_cls: 0.2701  loss_box_reg: 0.5646  loss_rpn_cls: 0.005594  loss_rpn_loc: 0.008735    time: 0.4443  last_time: 0.4686  data_time: 0.0059  last_data_time: 0.0059   lr: 7.4925e-05  max_mem: 2426M\n",
            "[01/19 16:23:48 d2.utils.events]:  eta: 0:04:55  iter: 319  total_loss: 0.8672  loss_cls: 0.2561  loss_box_reg: 0.59  loss_rpn_cls: 0.008675  loss_rpn_loc: 0.005886    time: 0.4448  last_time: 0.3915  data_time: 0.0074  last_data_time: 0.0054   lr: 7.992e-05  max_mem: 2426M\n",
            "[01/19 16:23:57 d2.utils.events]:  eta: 0:04:48  iter: 339  total_loss: 0.8017  loss_cls: 0.2087  loss_box_reg: 0.5673  loss_rpn_cls: 0.004895  loss_rpn_loc: 0.005922    time: 0.4459  last_time: 0.5479  data_time: 0.0059  last_data_time: 0.0088   lr: 8.4915e-05  max_mem: 2427M\n",
            "[01/19 16:24:06 d2.utils.events]:  eta: 0:04:41  iter: 359  total_loss: 0.8095  loss_cls: 0.1943  loss_box_reg: 0.609  loss_rpn_cls: 0.006083  loss_rpn_loc: 0.005965    time: 0.4462  last_time: 0.4615  data_time: 0.0061  last_data_time: 0.0049   lr: 8.991e-05  max_mem: 2427M\n",
            "[01/19 16:24:15 d2.utils.events]:  eta: 0:04:34  iter: 379  total_loss: 0.6619  loss_cls: 0.1391  loss_box_reg: 0.5076  loss_rpn_cls: 0.00361  loss_rpn_loc: 0.00587    time: 0.4473  last_time: 0.5049  data_time: 0.0063  last_data_time: 0.0055   lr: 9.4905e-05  max_mem: 2427M\n",
            "[01/19 16:24:24 d2.utils.events]:  eta: 0:04:26  iter: 399  total_loss: 0.7252  loss_cls: 0.1809  loss_box_reg: 0.5386  loss_rpn_cls: 0.003248  loss_rpn_loc: 0.005021    time: 0.4466  last_time: 0.5146  data_time: 0.0060  last_data_time: 0.0045   lr: 9.99e-05  max_mem: 2427M\n",
            "[01/19 16:24:33 d2.utils.events]:  eta: 0:04:17  iter: 419  total_loss: 0.7577  loss_cls: 0.165  loss_box_reg: 0.5917  loss_rpn_cls: 0.002346  loss_rpn_loc: 0.007035    time: 0.4463  last_time: 0.4593  data_time: 0.0071  last_data_time: 0.0063   lr: 0.0001049  max_mem: 2427M\n",
            "[01/19 16:24:42 d2.utils.events]:  eta: 0:04:08  iter: 439  total_loss: 0.6159  loss_cls: 0.1149  loss_box_reg: 0.4592  loss_rpn_cls: 0.00188  loss_rpn_loc: 0.005987    time: 0.4468  last_time: 0.4451  data_time: 0.0067  last_data_time: 0.0049   lr: 0.00010989  max_mem: 2427M\n",
            "[01/19 16:24:51 d2.utils.events]:  eta: 0:04:00  iter: 459  total_loss: 0.5645  loss_cls: 0.116  loss_box_reg: 0.4361  loss_rpn_cls: 0.002647  loss_rpn_loc: 0.005369    time: 0.4470  last_time: 0.5693  data_time: 0.0061  last_data_time: 0.0074   lr: 0.00011489  max_mem: 2427M\n",
            "[01/19 16:25:00 d2.utils.events]:  eta: 0:03:52  iter: 479  total_loss: 0.5555  loss_cls: 0.126  loss_box_reg: 0.4073  loss_rpn_cls: 0.001044  loss_rpn_loc: 0.007705    time: 0.4475  last_time: 0.4718  data_time: 0.0063  last_data_time: 0.0053   lr: 0.00011988  max_mem: 2428M\n",
            "WARNING [01/19 16:25:10 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[01/19 16:25:10 d2.data.datasets.coco]: Loaded 17 images in COCO format from /content/gdrive/My Drive/blues clues/datasets/blueprint_notes_rescaled/annotations/instances_val.json\n",
            "[01/19 16:25:10 d2.data.build]: Distribution of instances among all 2 categories:\n",
            "|   category    | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:----------:|:-------------|\n",
            "| General Not.. | 15           | Sheet Name | 17           |\n",
            "|               |              |            |              |\n",
            "|     total     | 32           |            |              |\n",
            "[01/19 16:25:10 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[01/19 16:25:10 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[01/19 16:25:10 d2.data.common]: Serializing 17 elements to byte tensors and concatenating them all ...\n",
            "[01/19 16:25:10 d2.data.common]: Serialized dataset takes 0.01 MiB\n",
            "WARNING [01/19 16:25:10 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
            "[01/19 16:25:10 d2.utils.events]:  eta: 0:03:43  iter: 499  total_loss: 0.4946  loss_cls: 0.1078  loss_box_reg: 0.3762  loss_rpn_cls: 0.003667  loss_rpn_loc: 0.007366    time: 0.4482  last_time: 0.4279  data_time: 0.0070  last_data_time: 0.0058   lr: 0.00012488  max_mem: 2428M\n",
            "[01/19 16:25:19 d2.utils.events]:  eta: 0:03:34  iter: 519  total_loss: 0.4185  loss_cls: 0.08758  loss_box_reg: 0.3102  loss_rpn_cls: 0.001219  loss_rpn_loc: 0.006359    time: 0.4475  last_time: 0.4290  data_time: 0.0057  last_data_time: 0.0100   lr: 0.00012987  max_mem: 2428M\n",
            "[01/19 16:25:28 d2.utils.events]:  eta: 0:03:26  iter: 539  total_loss: 0.327  loss_cls: 0.06945  loss_box_reg: 0.2339  loss_rpn_cls: 0.001267  loss_rpn_loc: 0.005379    time: 0.4482  last_time: 0.4654  data_time: 0.0065  last_data_time: 0.0060   lr: 0.00013487  max_mem: 2428M\n",
            "[01/19 16:25:37 d2.utils.events]:  eta: 0:03:17  iter: 559  total_loss: 0.3935  loss_cls: 0.1077  loss_box_reg: 0.2832  loss_rpn_cls: 0.003184  loss_rpn_loc: 0.005472    time: 0.4481  last_time: 0.3743  data_time: 0.0063  last_data_time: 0.0050   lr: 0.00013986  max_mem: 2428M\n",
            "[01/19 16:25:46 d2.utils.events]:  eta: 0:03:07  iter: 579  total_loss: 0.323  loss_cls: 0.07709  loss_box_reg: 0.225  loss_rpn_cls: 0.001606  loss_rpn_loc: 0.006206    time: 0.4478  last_time: 0.4910  data_time: 0.0058  last_data_time: 0.0066   lr: 0.00014486  max_mem: 2428M\n",
            "[01/19 16:25:55 d2.utils.events]:  eta: 0:02:59  iter: 599  total_loss: 0.315  loss_cls: 0.07874  loss_box_reg: 0.2234  loss_rpn_cls: 0.001864  loss_rpn_loc: 0.006759    time: 0.4479  last_time: 0.4522  data_time: 0.0067  last_data_time: 0.0054   lr: 0.00014985  max_mem: 2428M\n",
            "[01/19 16:26:04 d2.utils.events]:  eta: 0:02:50  iter: 619  total_loss: 0.2818  loss_cls: 0.05845  loss_box_reg: 0.2053  loss_rpn_cls: 0.0004459  loss_rpn_loc: 0.004486    time: 0.4482  last_time: 0.4404  data_time: 0.0066  last_data_time: 0.0054   lr: 0.00015485  max_mem: 2428M\n",
            "[01/19 16:26:13 d2.utils.events]:  eta: 0:02:41  iter: 639  total_loss: 0.2398  loss_cls: 0.064  loss_box_reg: 0.1639  loss_rpn_cls: 0.000765  loss_rpn_loc: 0.005853    time: 0.4485  last_time: 0.4814  data_time: 0.0054  last_data_time: 0.0052   lr: 0.00015984  max_mem: 2428M\n",
            "[01/19 16:26:22 d2.utils.events]:  eta: 0:02:32  iter: 659  total_loss: 0.2616  loss_cls: 0.06891  loss_box_reg: 0.1917  loss_rpn_cls: 0.001108  loss_rpn_loc: 0.004561    time: 0.4486  last_time: 0.4149  data_time: 0.0076  last_data_time: 0.0049   lr: 0.00016484  max_mem: 2428M\n",
            "[01/19 16:26:31 d2.utils.events]:  eta: 0:02:23  iter: 679  total_loss: 0.2614  loss_cls: 0.06212  loss_box_reg: 0.1756  loss_rpn_cls: 0.0002298  loss_rpn_loc: 0.004373    time: 0.4488  last_time: 0.3209  data_time: 0.0062  last_data_time: 0.0054   lr: 0.00016983  max_mem: 2428M\n",
            "[01/19 16:26:40 d2.utils.events]:  eta: 0:02:14  iter: 699  total_loss: 0.2337  loss_cls: 0.06307  loss_box_reg: 0.1734  loss_rpn_cls: 0.0001606  loss_rpn_loc: 0.004283    time: 0.4485  last_time: 0.4162  data_time: 0.0058  last_data_time: 0.0048   lr: 0.00017483  max_mem: 2428M\n",
            "[01/19 16:26:49 d2.utils.events]:  eta: 0:02:05  iter: 719  total_loss: 0.2496  loss_cls: 0.0644  loss_box_reg: 0.1781  loss_rpn_cls: 0.0003004  loss_rpn_loc: 0.00381    time: 0.4489  last_time: 0.4526  data_time: 0.0064  last_data_time: 0.0047   lr: 0.00017982  max_mem: 2428M\n",
            "[01/19 16:26:58 d2.utils.events]:  eta: 0:01:56  iter: 739  total_loss: 0.2163  loss_cls: 0.05068  loss_box_reg: 0.1648  loss_rpn_cls: 0.0001429  loss_rpn_loc: 0.00462    time: 0.4493  last_time: 0.3787  data_time: 0.0061  last_data_time: 0.0063   lr: 0.00018482  max_mem: 2428M\n",
            "[01/19 16:27:07 d2.utils.events]:  eta: 0:01:47  iter: 759  total_loss: 0.2064  loss_cls: 0.05923  loss_box_reg: 0.146  loss_rpn_cls: 0.000369  loss_rpn_loc: 0.004436    time: 0.4486  last_time: 0.3713  data_time: 0.0054  last_data_time: 0.0059   lr: 0.00018981  max_mem: 2428M\n",
            "[01/19 16:27:16 d2.utils.events]:  eta: 0:01:38  iter: 779  total_loss: 0.2517  loss_cls: 0.06073  loss_box_reg: 0.178  loss_rpn_cls: 0.0003512  loss_rpn_loc: 0.004403    time: 0.4487  last_time: 0.3466  data_time: 0.0056  last_data_time: 0.0057   lr: 0.00019481  max_mem: 2428M\n",
            "[01/19 16:27:26 d2.utils.events]:  eta: 0:01:29  iter: 799  total_loss: 0.1802  loss_cls: 0.05118  loss_box_reg: 0.1325  loss_rpn_cls: 0.0003719  loss_rpn_loc: 0.003024    time: 0.4500  last_time: 0.6722  data_time: 0.0103  last_data_time: 0.0255   lr: 0.0001998  max_mem: 2428M\n",
            "[01/19 16:27:35 d2.utils.events]:  eta: 0:01:20  iter: 819  total_loss: 0.2138  loss_cls: 0.05064  loss_box_reg: 0.1555  loss_rpn_cls: 0.0001933  loss_rpn_loc: 0.00411    time: 0.4499  last_time: 0.4415  data_time: 0.0059  last_data_time: 0.0052   lr: 0.0002048  max_mem: 2428M\n",
            "[01/19 16:27:44 d2.utils.events]:  eta: 0:01:11  iter: 839  total_loss: 0.2206  loss_cls: 0.05748  loss_box_reg: 0.1619  loss_rpn_cls: 0.0008256  loss_rpn_loc: 0.004154    time: 0.4500  last_time: 0.3704  data_time: 0.0070  last_data_time: 0.0058   lr: 0.00020979  max_mem: 2428M\n",
            "[01/19 16:27:53 d2.utils.events]:  eta: 0:01:02  iter: 859  total_loss: 0.1911  loss_cls: 0.05219  loss_box_reg: 0.1344  loss_rpn_cls: 0.0001252  loss_rpn_loc: 0.003497    time: 0.4500  last_time: 0.4747  data_time: 0.0068  last_data_time: 0.0050   lr: 0.00021479  max_mem: 2428M\n",
            "[01/19 16:28:02 d2.utils.events]:  eta: 0:00:54  iter: 879  total_loss: 0.2181  loss_cls: 0.05022  loss_box_reg: 0.1526  loss_rpn_cls: 0.0003123  loss_rpn_loc: 0.003867    time: 0.4503  last_time: 0.4215  data_time: 0.0059  last_data_time: 0.0063   lr: 0.00021978  max_mem: 2428M\n",
            "[01/19 16:28:12 d2.utils.events]:  eta: 0:00:45  iter: 899  total_loss: 0.1955  loss_cls: 0.05146  loss_box_reg: 0.1385  loss_rpn_cls: 0.000332  loss_rpn_loc: 0.003702    time: 0.4505  last_time: 0.4522  data_time: 0.0071  last_data_time: 0.0060   lr: 0.00022478  max_mem: 2428M\n",
            "[01/19 16:28:21 d2.utils.events]:  eta: 0:00:36  iter: 919  total_loss: 0.1869  loss_cls: 0.03738  loss_box_reg: 0.1418  loss_rpn_cls: 0.0002185  loss_rpn_loc: 0.004003    time: 0.4506  last_time: 0.4379  data_time: 0.0063  last_data_time: 0.0067   lr: 0.00022977  max_mem: 2428M\n",
            "[01/19 16:28:30 d2.utils.events]:  eta: 0:00:27  iter: 939  total_loss: 0.1902  loss_cls: 0.05248  loss_box_reg: 0.1424  loss_rpn_cls: 0.0001073  loss_rpn_loc: 0.00312    time: 0.4505  last_time: 0.3977  data_time: 0.0056  last_data_time: 0.0054   lr: 0.00023477  max_mem: 2428M\n",
            "[01/19 16:28:39 d2.utils.events]:  eta: 0:00:18  iter: 959  total_loss: 0.1964  loss_cls: 0.04391  loss_box_reg: 0.1486  loss_rpn_cls: 0.0001878  loss_rpn_loc: 0.004472    time: 0.4507  last_time: 0.5069  data_time: 0.0072  last_data_time: 0.0061   lr: 0.00023976  max_mem: 2428M\n",
            "[01/19 16:28:48 d2.utils.events]:  eta: 0:00:09  iter: 979  total_loss: 0.1631  loss_cls: 0.0444  loss_box_reg: 0.1102  loss_rpn_cls: 0.0002542  loss_rpn_loc: 0.002392    time: 0.4508  last_time: 0.5008  data_time: 0.0055  last_data_time: 0.0056   lr: 0.00024476  max_mem: 2428M\n",
            "[01/19 16:28:57 d2.utils.events]:  eta: 0:00:00  iter: 999  total_loss: 0.1712  loss_cls: 0.04208  loss_box_reg: 0.1237  loss_rpn_cls: 5.236e-05  loss_rpn_loc: 0.003003    time: 0.4503  last_time: 0.3232  data_time: 0.0057  last_data_time: 0.0057   lr: 0.00024975  max_mem: 2428M\n",
            "[01/19 16:28:58 d2.engine.hooks]: Overall training speed: 998 iterations in 0:07:29 (0.4504 s / it)\n",
            "[01/19 16:28:58 d2.engine.hooks]: Total training time: 0:07:37 (0:00:08 on hooks)\n",
            "WARNING [01/19 16:28:58 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[01/19 16:28:58 d2.data.datasets.coco]: Loaded 17 images in COCO format from /content/gdrive/My Drive/blues clues/datasets/blueprint_notes_rescaled/annotations/instances_val.json\n",
            "[01/19 16:28:58 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[01/19 16:28:58 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[01/19 16:28:58 d2.data.common]: Serializing 17 elements to byte tensors and concatenating them all ...\n",
            "[01/19 16:28:58 d2.data.common]: Serialized dataset takes 0.01 MiB\n",
            "WARNING [01/19 16:28:58 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
            "\n",
            "Training finished.\n",
            "To see training graphs, run the following command in your terminal:\n",
            "tensorboard --logdir /content/drive/MyDrive/output_blueprints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model saved to: {cfg.OUTPUT_DIR}\")\n",
        "print(f\"Final model: {cfg.OUTPUT_DIR}/model_final.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M_IvdKGDzhA",
        "outputId": "b8a804d0-a44d-4bfd-926c-002217eb5466"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/output_blueprints\n",
            "Final model: /content/drive/MyDrive/output_blueprints/model_final.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qtNUWIaDGNyP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}